{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFdtzftKj9VGzras5r41zU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raz0208/ModernBERT/blob/main/ModernBERT_TokenEmbedding_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract embedding form inpot text using ModernBERT Version 1"
      ],
      "metadata": {
        "id": "wBPYTlRkw_zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "9-ZP6xJPxKE0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load NLP and ModernBert models"
      ],
      "metadata": {
        "id": "m9D7ByFGxVTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ModernBERT tokenizer and model from Hugging Face\n",
        "MODEL_NAME = \"answerdotai/ModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "60H3zDHCxRuW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract emmbedings based on full text"
      ],
      "metadata": {
        "id": "A3rfDOmqxzXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get inpout text and return full text embedding\n",
        "def get_text_embedding(text):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # Forward pass to get hidden states\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the embeddings (use CLS token for sentence-level embedding)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # shape: [batch_size, hidden_size]\n",
        "\n",
        "    return cls_embedding.squeeze().numpy()"
      ],
      "metadata": {
        "id": "V0vUQ6Zfxy7-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### --- ### Sample text for test ### --- ###\n",
        "\n",
        "# 1- This is an application about Breast Cancer.\n",
        "# 2- Treating high blood pressure, high blood lipids, diabetes.\n",
        "# 3- Heart failure, heart attack, stroke, aneurysm, peripheral artery disease, sudden cardiac arrest. Deaths: 17.9 million / 32% (2015)"
      ],
      "metadata": {
        "id": "JtJfbcuIyHW2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exacute the app and get output"
      ],
      "metadata": {
        "id": "rwtc54A5zDAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage (Sentence: This is an application about Breast Cancer.)\n",
        "if __name__ == \"__main__\":\n",
        "    user_text = input(\"Enter your text: \")\n",
        "\n",
        "    # Get sentence embedding\n",
        "    full_text_embedding = get_text_embedding(user_text)\n",
        "    print(\"\\nSentence Embedding vector shape:\", full_text_embedding.shape)\n",
        "    print(\"Sentence Embedding (first 10 values):\", full_text_embedding[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDLS5aPhxtUW",
        "outputId": "790ab159-fa5b-4f49-c2f8-de4b24bd8d47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text: This is an application about Breast Cancer.\n",
            "\n",
            "Sentence Embedding vector shape: (768,)\n",
            "Sentence Embedding (first 10 values): [ 0.42236355 -0.8862073  -0.6536694  -0.2981413  -0.5874422  -0.720903\n",
            " -0.8588484  -0.89695704  0.5856571  -0.9214181 ]\n"
          ]
        }
      ]
    }
  ]
}